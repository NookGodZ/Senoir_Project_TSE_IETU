{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69d4bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python pandas mediapipe numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad009e2",
   "metadata": {},
   "source": [
    "# Collect sample situation image from Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5482a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e5650a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vedio_name = 'VEDIO/Nonlight.mp4' # Chage Input Vedio Path Here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a264c784",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv2.VideoCapture(vedio_name)\n",
    "vid.set(3, 1280)\n",
    "vid.set(4, 720)\n",
    "while(True):\n",
    "    ret, frame = vid.read()\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        out = cv2.imwrite('capture1.jpg', frame)\n",
    "        break\n",
    "vid.release()\n",
    "# Destroy all the windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8826f78",
   "metadata": {},
   "source": [
    "# Sketch square Working space (Packing) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cead0d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.imread('capture1.jpg',cv2.IMREAD_COLOR)\n",
    "x_w,y_w,w_w,h_w = cv2.selectROI(cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525f1c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('capture1.jpg')\n",
    "starting_coordinate = (x_w,y_w)\n",
    "ending_coordinate = (w_w+x_w,h_w+y_w)\n",
    "color = (255,0,0)\n",
    "new_image = cv2.rectangle(img, starting_coordinate , ending_coordinate, color)\n",
    "\n",
    "cv2.imshow('image', img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "out_2 = cv2.imwrite('capture2.jpg', new_image)\n",
    "\n",
    "print(f'{x_w,y_w,w_w,h_w}')\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a9db01",
   "metadata": {},
   "source": [
    "# Sketch square Drop-off  (Product placement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244d88ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.imread('capture2.jpg',cv2.IMREAD_COLOR)\n",
    "x_o,y_o,w_o,h_o = cv2.selectROI(cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9904326",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('capture2.jpg')\n",
    "starting_coordinate = (x_o,y_o)\n",
    "ending_coordinate = (w_o+x_o,h_o+y_o)\n",
    "color = (0,0,255)\n",
    "new_image = cv2.rectangle(img, starting_coordinate , ending_coordinate, color)\n",
    "\n",
    "cv2.imshow('image', img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "out_2 = cv2.imwrite('capture3.jpg', new_image)\n",
    "print(f'{x_o,y_o,w_o,h_o}')\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48ae60e",
   "metadata": {},
   "source": [
    "# Run Algorithm & MediaPipe Holistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59d877c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put input coordinate here \n",
    "\n",
    "x_w,y_w,w_w,h_w = 58, 105, 554, 835\n",
    "\n",
    "x_o,y_o,w_o,h_o = 1240, 90, 654, 910\n",
    "\n",
    "vedio_name = 'VEDIO/Nonlight.mp4'\n",
    "\n",
    "cycle = 10 # Cycle time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6c1cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import time\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose\n",
    "list_for_data=[]\n",
    "first_station = []\n",
    "second_station = []\n",
    "pick = 0\n",
    "drop = 1\n",
    "cap = cv2.VideoCapture(vedio_name)\n",
    "# Get the frame rate (frames per second) and number of frames\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "# Calculate the duration of the video in seconds\n",
    "duration = num_frames / fps\n",
    "# Initialize the timer\n",
    "timer = 0\n",
    "with mp_pose.Pose(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        # Increment the timer by the delay between frames\n",
    "        timer += int(1000 / fps)\n",
    "        # Calculate the current time in seconds\n",
    "        current_time = timer / 1000\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "                  # If loading a video, use 'break' instead of 'continue'.\n",
    "            cv2.destroyAllWindows() \n",
    "            break\n",
    "        # To improve performance, optionally mark the image as not writeable to\n",
    "        # pass by reference.\n",
    "        image.flags.writeable = False\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image)\n",
    "        # Draw the pose annotation on the image.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image,\n",
    "            results.pose_landmarks,\n",
    "            mp_pose.POSE_CONNECTIONS,\n",
    "            landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "        lmlist = []\n",
    "        if results.pose_landmarks:\n",
    "            for ide, lm in enumerate(results.pose_landmarks.landmark):\n",
    "                h,w,c = image.shape\n",
    "                cx,cy = int(lm.x*w),int(lm.y*h)\n",
    "                lmlist.append([ide,cx,cy])\n",
    "                list_for_data.append([ide,cx,cy])\n",
    "            # Flip the image horizontally for a selfie-view display.\n",
    "        # Flip the image horizontally for a selfie-view display.\n",
    "        cv2.putText(image, f\"Time: {current_time:.2f}/{duration:.0f}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        if len(lmlist)!=0:\n",
    "            body = []\n",
    "            for k in range(len(lmlist[0])):\n",
    "                result = lmlist[11][k] + lmlist[12][k] + lmlist[23][k] + lmlist[24][k]\n",
    "                body.append(result/4)\n",
    "            if y_o+h_o >= body[2] >= y_o and x_o <= body[1] <=x_o+w_o:\n",
    "                if drop == 0 :\n",
    "                    second_station.append(current_time)\n",
    "                    drop = 1\n",
    "                    pick = 0\n",
    "                    print(f'second_station:{current_time}')\n",
    "            elif y_w+h_w >= body[2] >= y_w and x_w <= body[1] <=x_w+w_w:\n",
    "                if pick == 0 :\n",
    "                    first_station.append(current_time)\n",
    "                    pick = 1\n",
    "                    drop = 0\n",
    "                    print(f'first_station:{current_time}')\n",
    "                if len(first_station) == cycle+1 :\n",
    "                    break\n",
    "            #cv2.imshow('MediaPipe Pose',image)\n",
    "            if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "                cv2.destroyAllWindows() \n",
    "                break\n",
    "        cv2.imshow('frame', image) \n",
    "cv2.destroyAllWindows() \n",
    "cap.release()\n",
    "\n",
    "#### Transfrom data to Excel \n",
    "staion =first_station\n",
    "cycle = []\n",
    "for i in range(len(staion)-1):\n",
    "    cycle.append(abs(staion[i+1]-staion[i]))\n",
    "DATA_CYCLE = pd.DataFrame({'Cycle Time':cycle})\n",
    "DATA_CYCLE.to_excel('Cycle_time.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360bb4fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daad706a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53062a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bcf555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c772f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
